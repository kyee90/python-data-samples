{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample 2 of Exploratory Data Analysis\n",
    "### EDA of a dataset of house prices and various attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "path = os.getcwd()\n",
    "df = pd.read_csv(path+'/Data/House_Price.csv')\n",
    "\n",
    "#   splitting dataset into 70-30 train-test\n",
    "train, test = tts(df, test_size=0.3, random_state=309)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Delete duplicate data-points\n",
    "train = train.drop_duplicates()\n",
    "test = test.drop_duplicates()\n",
    "\n",
    "##  handle missing data - remove columns with >50% NA\n",
    "def remove_cols(dataset):\n",
    "    remove_cols = []\n",
    "    null_columns = dataset.isna().sum()\n",
    "    null_columns = null_columns[null_columns != 0].sort_values(ascending=False)\n",
    "    null_columns = null_columns.to_dict()\n",
    "\n",
    "    for key, value in null_columns.items():\n",
    "        pct = value / len(dataset)\n",
    "        if pct >= 0.5:\n",
    "            remove_cols.append(key)\n",
    "\n",
    "    dataset = dataset.drop(columns=remove_cols)\n",
    "    return dataset\n",
    "\n",
    "test = remove_cols(test)\n",
    "train = remove_cols(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "#   encode FireplaceQu into ordinal values e.g. 0 = none 5 = best fireplace\n",
    "enc = OrdinalEncoder(categories=[[0,'Po', 'Fa', 'TA', 'Gd', 'Ex']])\n",
    "#   replace NAs with 0\n",
    "X = np.array(train['FireplaceQu'].fillna(0))\n",
    "X = X.reshape(-1,1)\n",
    "train['FireplaceQu'] = enc.fit_transform(X)\n",
    "\n",
    "\n",
    "#   encode Bsmt Qual/Cond into ordinal values\n",
    "X = np.array(train['BsmtQual'].fillna(0))\n",
    "X = X.reshape(-1,1)\n",
    "train['BsmtQual'] = enc.fit_transform(X)\n",
    "X = np.array(train['BsmtCond'].fillna(0))\n",
    "X = X.reshape(-1,1)\n",
    "train['BsmtCond'] = enc.fit_transform(X)\n",
    "\n",
    "#   encode Garage Qual/Cond into ordinal values\n",
    "X = np.array(train['GarageQual'].fillna(0))\n",
    "X = X.reshape(-1,1)\n",
    "train['GarageQual'] = enc.fit_transform(X)\n",
    "X = np.array(train['GarageCond'].fillna(0))\n",
    "X = X.reshape(-1,1)\n",
    "train['GarageCond'] = enc.fit_transform(X)\n",
    "\n",
    "#   replace NAs with 0 in LotFrontage\n",
    "train['LotFrontage'] = train['LotFrontage'].fillna(0)\n",
    "train['LotFrontage']\n",
    "\n",
    "#   drop 'GarageType', 'GarageYrBlt', 'GarageFinish'\n",
    "garage_drop = ['GarageType', 'GarageYrBlt', 'GarageFinish']\n",
    "train = train.drop(columns=garage_drop)\n",
    "\n",
    "#   drop 'BsmtExposure', 'BsmtFinType1', 'BsmtFintype2'\n",
    "bsmt_drop = ['BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']\n",
    "train = train.drop(columns=bsmt_drop)\n",
    "\n",
    "#   replace NAs in 'MasVnrType' and 'MasVnrArea'\n",
    "train['MasVnrType'] = train['MasVnrType'].fillna('None')\n",
    "train['MasVnrArea'] = train['MasVnrArea'].fillna(0)\n",
    "\n",
    "#   replace NAs in 'Electrical' with most common\n",
    "train['Electrical'] = train['Electrical'].fillna('SBrkr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   TEST Set\n",
    "#   encode FireplaceQu into ordinal values e.g. 0 = none 5 = best fireplace\n",
    "enc = OrdinalEncoder(categories=[[0,'Po', 'Fa', 'TA', 'Gd', 'Ex']])\n",
    "#   replace NAs with 0\n",
    "X = np.array(test['FireplaceQu'].fillna(0))\n",
    "X = X.reshape(-1,1)\n",
    "test['FireplaceQu'] = enc.fit_transform(X)\n",
    "\n",
    "\n",
    "#   encode Bsmt Qual/Cond into ordinal values\n",
    "X = np.array(test['BsmtQual'].fillna(0))\n",
    "X = X.reshape(-1,1)\n",
    "test['BsmtQual'] = enc.fit_transform(X)\n",
    "X = np.array(test['BsmtCond'].fillna(0))\n",
    "X = X.reshape(-1,1)\n",
    "test['BsmtCond'] = enc.fit_transform(X)\n",
    "\n",
    "#   encode Garage Qual/Cond into ordinal values\n",
    "X = np.array(test['GarageQual'].fillna(0))\n",
    "X = X.reshape(-1,1)\n",
    "test['GarageQual'] = enc.fit_transform(X)\n",
    "X = np.array(test['GarageCond'].fillna(0))\n",
    "X = X.reshape(-1,1)\n",
    "test['GarageCond'] = enc.fit_transform(X)\n",
    "\n",
    "#   replace NAs with 0 in LotFrontage\n",
    "test['LotFrontage'] = test['LotFrontage'].fillna(0)\n",
    "test['LotFrontage']\n",
    "\n",
    "#   drop 'GarageType', 'GarageYrBlt', 'GarageFinish'\n",
    "garage_drop = ['GarageType', 'GarageYrBlt', 'GarageFinish']\n",
    "test = test.drop(columns=garage_drop)\n",
    "\n",
    "#   drop 'BsmtExposure', 'BsmtFinType1', 'BsmtFintype2'\n",
    "bsmt_drop = ['BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']\n",
    "test = test.drop(columns=bsmt_drop)\n",
    "\n",
    "#   replace NAs in 'MasVnrType' and 'MasVnrArea'\n",
    "test['MasVnrType'] = test['MasVnrType'].fillna('None')\n",
    "test['MasVnrArea'] = test['MasVnrArea'].fillna(0)\n",
    "\n",
    "#   replace NAs in 'Electrical' with most common\n",
    "test['Electrical'] = test['Electrical'].fillna('SBrkr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#   data normalisation for our top 5 features 'OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea', 'TotalBsmtSF'\n",
    "top5features = ['OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea', 'TotalBsmtSF']\n",
    "X = train[top5features]\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "train[top5features] = X\n",
    "\n",
    "#   now test set\n",
    "X = test[top5features]\n",
    "X = scaler.fit_transform(X)\n",
    "test[top5features] = X\n",
    "\n",
    "#   remove redundant columns\n",
    "redundant_columns = ['Id', 'MSZoning', 'Street', 'LotShape', 'LandContour','LandSlope','Condition1','Condition2']\n",
    "train = train.drop(columns=redundant_columns)\n",
    "test = test.drop(columns=redundant_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   saving processed data to CSV\n",
    "train.to_csv('training-processed.csv', index=False)\n",
    "test.to_csv('test-processed.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dimensionality reduction techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "##  dimensionality reduction / feature selection\n",
    "\n",
    "#   select for numeric only features\n",
    "numer = train.select_dtypes(include=['float','int'])\n",
    "price = train['SalePrice']\n",
    "#   scale all features to 0-1\n",
    "scaler = StandardScaler()\n",
    "numer = scaler.fit_transform(numer)\n",
    "numer = pd.DataFrame(data=numer)\n",
    "\n",
    "#   principal components analysis\n",
    "pca = decomposition.PCA(n_components=5)\n",
    "pca.fit(numer)\n",
    "pca_X = pca.transform(numer)\n",
    "df = pd.DataFrame(data = pca_X,columns = ['PC1', 'PC2','PC3','PC4','PC5'])\n",
    "target = pd.Series(price, name='saleprice')\n",
    "result_df = pd.concat([df, target], axis=1)\n",
    "print(result_df.head())\n",
    "print()\n",
    "\n",
    "#   independent components analysis\n",
    "ica = decomposition.FastICA(n_components=5,whiten='unit-variance', max_iter=1000)\n",
    "ica.fit(numer)\n",
    "ica_X = ica.transform(numer)\n",
    "df = pd.DataFrame(data = ica_X,columns = ['PC1', 'PC2','PC3','PC4','PC5'])\n",
    "result_df = pd.concat([df, target], axis=1)\n",
    "print(result_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data mining preprocessed data using machine learning methods.\n",
    "\n",
    "Using ordinary linear regression and ridge regression (with alpha=0.5 ) for predicting the house prices. Comparing their results regarding the mean squared errors on the training set and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Mean squared error: 0.00\n",
      "Ridge reg Mean squared error: 0.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#   linear regression\n",
    "reg = linear_model.LinearRegression()\n",
    "train_X = train.iloc[:,0:len(train.columns)-1]\n",
    "train_X = train.select_dtypes(include=['float64','int'])\n",
    "train_Y = train.iloc[:,len(train.columns)-1]\n",
    "#train_X\n",
    "reg.fit(train_X, train_Y)\n",
    "test_X = test.iloc[:,0:len(train.columns)-1]\n",
    "test_X = test.select_dtypes(include=['float64','int'])\n",
    "predict_test = reg.predict(test_X)\n",
    "\n",
    "test_Y = test.iloc[:,len(train.columns)-1]\n",
    "print(\"LR Mean squared error: %.2f\" % mean_squared_error(predict_test, test_Y))\n",
    "\n",
    "#   ridge regression\n",
    "ridge = linear_model.Ridge(alpha=0.5)\n",
    "ridge.fit(train_X, train_Y)\n",
    "ridge_pred = ridge.predict(test_X)\n",
    "print(\"Ridge reg Mean squared error: %.2f\" % mean_squared_error(ridge_pred, test_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Random Forest, comparing the results of linear regression and ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Mean squared error: 6313780108.17\n",
      "(438,)\n",
      "(438,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_cls = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "rf_cls.fit(train_X, train_Y)\n",
    "rf_pred = rf_cls.predict(test_X)\n",
    "print(\"Random Forest Mean squared error: %.2f\" % mean_squared_error(rf_pred, test_Y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
